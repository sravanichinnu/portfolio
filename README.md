## Selected Projects in Data Science, Machine Learning, and NLP
---
### Forecasting Energy Consumption
The goal of this project to perform high level exploratory data analysis and build different time series models which will help in forecasting the energy consumtpion in future.

<img src="images/img1.png?raw=true" />

[![](https://img.shields.io/badge/Python-white?logo=Python)](#) [![](https://img.shields.io/badge/Google--Colab-white?logo=Google%20Colab)](#) [![](https://img.shields.io/badge/pandas-white?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMIAAAEDCAMAAABQ/CumAAAAeFBMVEX///8TB1QAAEb/ygDnBIgPAFLNzNYTAFnQ0NgMAFcAAETb2eP39/oUBlfV1N7/xwDmAID/9tfLydcjG17/4Yz//vbCwM3ykcL61OfoBIwyKmgAADYAAE0AAErx8PTIxdT/+un/34T85/Lyir/lAHv50eX+9fkpH2Ma8J+4AAACEklEQVR4nO3dzVIaQRSAUYNCEIGoiYmJivnP+79hFrmLVHELZ6pnmG483xqaPruh5lb32ZkkSZIkSZIkvb52z7dZU2+rT4uH2X6rx6m31afF7M1+87dTb6tPCDWEUEMINYRQQ5MS1tu0nqtMSrhKn26e1v1WmZawyn58g4DQL4QIoSyECKEshAihLIQIoSyECKEshAihLIQIoSyECKEshAihLIQIoSyECOFA6cvM5a4nYb29yjoO4WmVvM58WPQkbF8e+RqPcDlPVp4t+xLS/W0QEBCqI8yTLpsizN8n/WmJ0CEEBAQEBAQEBIT2CF+/fci6a4hw8y7rvC3CeRYCAgICAgICAgICAgICwlCEtJYIdzdp/3+kdkKHToFQ+RjJMCEcCKF7CAdC6B7CgRC6Nylh9zGtJUJ6uNCsnsOFhhkvPAHC9x+fsloi/Pp5nXTREuH++iLpMwICAgICAgICAgICAgKC/87R7/u0lggdQkBAQEBAQEB4dYQON67UTqh9KuwkDlRBQED4R8gOF5o3Rdh8yepLGO0ez6MNPO+WQ9w3NilhvBAihLIQIoSyECKEshAihLIQIoSyECKEshAihLIQIoSyECKEshAihLIQIoSyEKJt+lL0SNeADUR4TG9cGWXHew10AkPP4aRBO9ohEuOFUEMINYRQQwg1dAKEDvd41t5t2u7lL0qSJEmSJEnSyfUXeomSFq0EzbkAAAAASUVORK5CYII=)](#) [![](https://img.shields.io/badge/sklearn-white?logo=scikit-learn)](#) [![](https://img.shields.io/badge/TensorFlow-white?logo=TensorFlow)](#)

[View code on Colab](https://colab.research.google.com/drive/12t4xi6aQPqUbIEAZOjPsRxsOnn3FYj00#scrollTo=tODy1xDxmD4b)

---
### Hospital Database Management System
Developed a Hospital Database Management System using MySQL and Python to provide an easy-to-use and efficient solution for managing hospital data. I implemented a command line interface that offers a menu-driven output, making it simpler for users to interact with the system. This project followed an iterative development process, starting with requirements gathering, database design, implementation, and testing.

[![](https://img.shields.io/badge/Python-white?logo=Python)](#) [![](https://img.shields.io/badge/MySQL-white?logo=MySQL)](#)


[View code on Github](https://github.com/sravanichinnu/Hospital-Database-Management-System)

---
### Coffee Sales Dashboard using Excel
The project involves creating a comprehensive excel dashboard to analyze and visualize coffee sales performance. This dashboard provides insights into sales across regions, and products with key metrics including total sales, growth trends, and top5 customers.

<img src="images/coffee_sales_dashboard.png?raw=true" />

[![Excel Badge](https://img.shields.io/badge/Excel-white?logo=Microsoft%20Excel&logoColor=black)](#) 

---
### Genre Identification and Song Similarity
This project involves study on how to visualize sound, understand what we hear and identify the features that determine and differentiate one song from another. This study uses feature extraction and classification to help group songs on a genre basis - songs that are highly similar instead of manual tags. The model identifies the similar song based on the input song which enhances user experience and increases artist recognition.

<img src="images/img2.png?raw=true" />

[![](https://img.shields.io/badge/Python-white?logo=Python)](#) [![](https://img.shields.io/badge/librosa-white?logo=librosa)](#) [![](https://img.shields.io/badge/Seaborn-white?logo=Seaborn)](#) [![](https://img.shields.io/badge/sklearn-white?logo=scikit-learn)](#)

[View code on Colab](https://colab.research.google.com/drive/1G_5Id5mjf0A5yzE_J1KFXrp7_3-9xZSW#scrollTo=uNg6dKy1zQie)

---
## Education
Master of Science, Data Science at Northeastern University, Boston, MA

Bachelor of Technology, Computer Science Technology, KL University, India

---
## Work Experience
### Data Engineer @ IQVIA (Contract)
Built scalable batch and real-time pipelines with PySpark, Kafka, and AWS Glue, cutting manual effort by 80%. Automated data quality checks, transformed XML/JSON into analytics-ready data in Redshift, and created QuickSight dashboards that boosted revenue by 10%.

---
### Sr Associate Data Engineer @ Travelers Insurance
Contributed to a major data mirgation project to transfer the data legacy SQL Server to AWS S3, improving accessibility and cutting infrastructure costs. Built PySpark-based workflows in Databricks and AWS Glue, implemented data quality checks reducing QA time by 10+ hours per week, and developed Snowflake automations. Delivered Power BI dashboards for real-time KPI and production monitoring, ensuring accuratr, actionable insights.

---
### Machine Learning Engineer Intern @ TRACT
Developed risk prediction models using advanced algorithms (Logistic Regression, Random Forest, XGBoost). Automated the entire ML workflow with AWS Lambda and Step Functions, improving efficiency and scalability. Enhanced model performance through hyperparameter tuning and collaborated with cross-functional teams to deliver robust end-to-end machine learning solutions that significantly improved risk assessment accuracy.
  
---
### Programmer Analyst @ Cognizant Technology Solutions
Automated and optimized data pipelines with Python, Airflow, and SQL, reducing processing time and manual work by 100+ hours. Built CI/CD systems using Git and Jenkins, managed ETL configs with MongoDB, and migrated legacy workflows to Azure data lakes for better scalability. Ensured smooth production by resolving issues and particiapting in code reviews.
  
---
### Python Developer Intern @ Cognizant Technology Solutions
Built a full-stack web application using Python (Flask/Django), JavaScript, and SQL, attracting 50k+ active users in the first month. Implemented dynamic SQL for bulk OLTP operations.

---
### Data Analytics Intern @ BSNL
Optimized SQL queries and automated tasks to analyze telecom data, reducing manual work. Builr Excel dashboards for customer metrics and ensured data quality through thorough validation.







